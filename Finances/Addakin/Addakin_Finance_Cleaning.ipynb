{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the packages that we need to conduct necesary cleaning and streamlit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import pdfplumber\n",
    "import streamlit as st\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all AMEX Statements and Cleaning Data to Desired Table Format \n",
    "#### Description, Amount, Category, Month, Day, Action\n",
    "\n",
    "Actions are powered by a categorization mapping .CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Description  Amount    Category     Month  \\\n",
      "0                                          UBER   16.39        Uber  February   \n",
      "1                                          UBER   20.93        Uber  February   \n",
      "2    Interest Charge on Pay Over Time Purchases   43.88        Fees  February   \n",
      "3    TST* MIKE'S BEER BARPITTSBURGH          PA    3.67         Bar  February   \n",
      "4                                          UBER   14.96        Uber  February   \n",
      "..                                          ...     ...         ...       ...   \n",
      "165  AplPay STARBUCKS    800-782-7282        WA   10.00         Bar  December   \n",
      "166  THE MERCHANT KITCHENBOSTON              MA   53.50  Restaurant  December   \n",
      "167  TST* CRAFT FOOD HALLBOSTON              MA   19.14  Restaurant  December   \n",
      "168  TST* TATTE BAKERY ONBOSTON              MA   14.04  Restaurant  December   \n",
      "169  MA MAISON 6500000034BOSTON              MA   85.00  Restaurant  December   \n",
      "\n",
      "     Day Action Statement  \n",
      "0      9  Spend      AMEX  \n",
      "1      9  Spend      AMEX  \n",
      "2      9  Spend      AMEX  \n",
      "3      9  Spend      AMEX  \n",
      "4      8  Spend      AMEX  \n",
      "..   ...    ...       ...  \n",
      "165   13  Spend      AMEX  \n",
      "166   13  Spend      AMEX  \n",
      "167   13  Spend      AMEX  \n",
      "168   13  Spend      AMEX  \n",
      "169   12  Spend      AMEX  \n",
      "\n",
      "[170 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# American Express Bank\n",
    "folder_path = \"/Users/addakinthomas/Desktop/Finances/Addakin/amex/\"\n",
    "dfs = []\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "\n",
    "        month_name = file.split(\"_\")[0]\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        dfs.append(df)\n",
    "\n",
    "df= pd.concat(dfs,ignore_index=True)\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce', format='%m/%d/%Y')\n",
    "\n",
    "# Extract Month Name and Day\n",
    "df['Month'] = df['Date'].dt.strftime('%B')  # \"January\"\n",
    "df['Day'] = df['Date'].dt.day  # Extracts day as an integer (1-31)\n",
    "df['Action'] = df['Amount'].apply(lambda x: 'Spend' if x > 0 else 'Income')\n",
    "\n",
    "# Read the spending categories file\n",
    "spending_categories = pd.read_csv(\"/Users/addakinthomas/Desktop/Finances/Addakin/spending_categories.csv\")\n",
    "\n",
    "# Create a dictionary for mapping\n",
    "category_mapping = dict(zip(spending_categories['name'], spending_categories['category']))\n",
    "\n",
    "# Map the 'Category' column in df to the new categories\n",
    "df['Category'] = df['Category'].map(category_mapping)\n",
    "df['Statement'] = 'AMEX'\n",
    "\n",
    "# Drop not needed column\n",
    "df1 = df.drop(columns=['Date', 'Account #', 'Card Member', 'Extended Details', 'Reference', 'Appears On Your Statement As', 'Address', 'City/State', 'Zip Code', 'Country'])\n",
    "\n",
    "# Display final DataFrame\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df1 outputted, cleaned AMEX table\n",
    "### next step is to do the same to Chase bank statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: january_2025.pdf\n",
      "Processing: february_2025.pdf\n",
      "                                          Description   Amount Category  \\\n",
      "0   American Express ACH Pmt M8014 Web ID: 2005032111    23.20    Other   \n",
      "1                               Remote Online Deposit     1.00    Other   \n",
      "2      Venmo Payment 1039105423155 Web ID: 3264681992    40.00    Other   \n",
      "3      Venmo Payment 1039105425873 Web ID: 3264681992    20.00    Other   \n",
      "4   Card Purchase 12/21 Draftkings 6179866744 MA C...    10.00    Other   \n",
      "..                                                ...      ...      ...   \n",
      "90  Card Purchase 02/16 Betrivers PA 8555851401 IL...    25.00    Other   \n",
      "91  Card Purchase 02/16 Betrivers PA 8555851401 IL...   100.00    Other   \n",
      "92  Payment Sent 02/18 Venmo *Will Dimond Visa Dir...  1682.00    Other   \n",
      "93          Tpg Products Sbtpg LLC PPD ID: 3722260102    84.98    Other   \n",
      "94         Betrivers PA Viatrustly Web ID: 1218965010   125.00    Other   \n",
      "\n",
      "       Month  Day  Action Statement  \n",
      "0   December   19   Spend     CHASE  \n",
      "1   December   23  Income     CHASE  \n",
      "2   December   23   Spend     CHASE  \n",
      "3   December   23   Spend     CHASE  \n",
      "4   December   23   Spend     CHASE  \n",
      "..       ...  ...     ...       ...  \n",
      "90  February   18   Spend     CHASE  \n",
      "91  February   18   Spend     CHASE  \n",
      "92  February   19   Spend     CHASE  \n",
      "93  February   20  Income     CHASE  \n",
      "94  February   20   Spend     CHASE  \n",
      "\n",
      "[95 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dq/yjshrdhd0l1_csn5j_xbm77h0000gn/T/ipykernel_14018/39363057.py:58: DeprecationWarning: Parsing dates involving a day of month without a year specified is ambiguious\n",
      "and fails to parse leap day. The default behavior will change in Python 3.15\n",
      "to either always raise an exception or to use a different default year (TBD).\n",
      "To avoid trouble, add a specific year to the input & format.\n",
      "See https://github.com/python/cpython/issues/70647.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], format='%m/%d')\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the folder containing the PDF files\n",
    "folder_path = \"/Users/addakinthomas/Desktop/Finances/Addakin/chase/\"\n",
    "\n",
    "# Initialize an empty list to store all transactions across multiple PDFs\n",
    "all_transactions = []\n",
    "\n",
    "# Loop through all PDF files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".pdf\"):  # Ensure we only process PDF files\n",
    "        pdf_path = os.path.join(folder_path, filename)\n",
    "        print(f\"Processing: {filename}\")\n",
    "\n",
    "        # Open the PDF\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            num_pages = len(pdf.pages)  # Get total number of pages\n",
    "            start_page = 1  # Page index for second page (0-based index)\n",
    "            end_page = num_pages - 1  # 2nd to last page\n",
    "\n",
    "            for page_num in range(start_page, end_page):  # Loop through selected pages\n",
    "                page = pdf.pages[page_num]\n",
    "                text = page.extract_text()\n",
    "\n",
    "                if text:\n",
    "                    # **Remove extra text before and after the transaction list**\n",
    "                    text = re.sub(r\".*?\\*start\\*transaction detail\", \"\", text, flags=re.DOTALL)  # Remove everything before \"*start*transaction detail\"\n",
    "                    text = re.sub(r\"\\*end\\*transac.*\", \"\", text, flags=re.DOTALL)  # Remove everything after \"*end*transac\"\n",
    "                    text = text.strip()  # Clean up leading/trailing whitespace\n",
    "\n",
    "                    # Regular expression to match transaction entries\n",
    "                    pattern = re.compile(\n",
    "                        r\"(\\d{2}/\\d{2})\\s+(.+?)\\s+([-]?\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?)\\s+(\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?)\"\n",
    "                    )\n",
    "\n",
    "                    # Extract transactions using regex\n",
    "                    transactions = pattern.findall(text)\n",
    "\n",
    "                    # Append transactions to the list, adding the file name for reference\n",
    "                    for transaction in transactions:\n",
    "                        all_transactions.append((filename,) + transaction)\n",
    "\n",
    "# Convert extracted data into a DataFrame\n",
    "df = pd.DataFrame(all_transactions, columns=[\"File\", \"Date\", \"Description\", \"Amount\", \"Balance\"])\n",
    "\n",
    "# Convert Amount and Balance to numeric values\n",
    "df[\"Amount\"] = df[\"Amount\"].str.replace(\",\", \"\").astype(float)\n",
    "df[\"Balance\"] = df[\"Balance\"].str.replace(\",\", \"\").astype(float)\n",
    "\n",
    "# Display the DataFrame\n",
    "\n",
    "df[\"Description\"] = df[\"Description\"]\n",
    "df[\"Amount\"] = df[\"Amount\"]\n",
    "df['Category'] = df['Description'].map(category_mapping).fillna('Other')\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%m/%d')\n",
    "df['Month'] = df['Date'].dt.strftime('%B')  # \"January\"\n",
    "df['Day'] = df['Date'].dt.day  # Extracts day as an integer (1-31)\n",
    "df['Action'] = df['Amount'].apply(lambda x: 'Spend' if x < 0 else 'Income')\n",
    "df['Amount'] = df['Amount'].abs()\n",
    "df['Statement'] = 'CHASE'\n",
    "df = df.drop(columns=['File', 'Date', 'Balance'])\n",
    "\n",
    "df2 = df\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### outputted df2 from chase bank, now union the tables together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Description   Amount Category  \\\n",
      "0                                                UBER    16.39     Uber   \n",
      "1                                                UBER    20.93     Uber   \n",
      "2          Interest Charge on Pay Over Time Purchases    43.88     Fees   \n",
      "3          TST* MIKE'S BEER BARPITTSBURGH          PA     3.67      Bar   \n",
      "4                                                UBER    14.96     Uber   \n",
      "..                                                ...      ...      ...   \n",
      "90  Card Purchase 02/16 Betrivers PA 8555851401 IL...    25.00    Other   \n",
      "91  Card Purchase 02/16 Betrivers PA 8555851401 IL...   100.00    Other   \n",
      "92  Payment Sent 02/18 Venmo *Will Dimond Visa Dir...  1682.00    Other   \n",
      "93          Tpg Products Sbtpg LLC PPD ID: 3722260102    84.98    Other   \n",
      "94         Betrivers PA Viatrustly Web ID: 1218965010   125.00    Other   \n",
      "\n",
      "       Month  Day  Action Statement  \n",
      "0   February    9   Spend      AMEX  \n",
      "1   February    9   Spend      AMEX  \n",
      "2   February    9   Spend      AMEX  \n",
      "3   February    9   Spend      AMEX  \n",
      "4   February    8   Spend      AMEX  \n",
      "..       ...  ...     ...       ...  \n",
      "90  February   18   Spend     CHASE  \n",
      "91  February   18   Spend     CHASE  \n",
      "92  February   19   Spend     CHASE  \n",
      "93  February   20  Income     CHASE  \n",
      "94  February   20   Spend     CHASE  \n",
      "\n",
      "[265 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "finances = pd.concat([df1, df2], ignore_index=False)\n",
    "print(finances)\n",
    "\n",
    "folder_path = \"/Users/addakinthomas/Desktop/Finances/Addakin/streamlit/\"\n",
    "df.to_csv(os.path.join(folder_path, \"finances.csv\"), index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### outputted df finances to power streamlit application\n",
    "\n",
    "use %%writefile app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define file path dynamically\n",
    "csv_file = \"\"\n",
    "feedback_folder = \"feedback\"\n",
    "feedback_file = os.path.join(feedback_folder, \"feedback.txt\")\n",
    "\n",
    "# Load CSV data safely\n",
    "def load_data():\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df.columns = df.columns.str.lower().str.strip()  # Normalize column names to lowercase and remove spaces\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        return None\n",
    "\n",
    "# Create feedback directory if not exists\n",
    "if not os.path.exists(feedback_folder):\n",
    "    os.makedirs(feedback_folder)\n",
    "\n",
    "# Streamlit UI\n",
    "st.set_page_config(layout=\"wide\")\n",
    "st.title(\"ðŸ“Š Addakin's Financial Overview\")\n",
    "\n",
    "df = load_data()\n",
    "\n",
    "if df is None:\n",
    "    st.error(f\"âŒ CSV file not found at: `{csv_file}`\")\n",
    "else:\n",
    "    months_ordered = [\"December\", \"January\", \"February\"]\n",
    "    available_months = [month for month in months_ordered if month.lower() in df['month'].dropna().str.lower().unique()]\n",
    "    \n",
    "    # Sidebar Filters\n",
    "    st.sidebar.header(\"ðŸ“… Filter by Month\")\n",
    "    selected_month = st.sidebar.radio(\"Select a month\", available_months)\n",
    "    if selected_month:\n",
    "        df = df[df['month'].str.lower() == selected_month.lower()]\n",
    "    \n",
    "    # Categorize \"Other\"\n",
    "    df.loc[df['category'].str.lower() == 'other', 'category'] = 'Other'\n",
    "    uncategorized_df = df[df['category'] == 'Other']\n",
    "    df = df[df['category'] != 'Other']\n",
    "    \n",
    "    # Tabs\n",
    "    tab1, tab2, tab3, tab4 = st.tabs([\"ðŸ’¸ Spending\", \"ðŸ’° Saving\", \"ðŸ“ˆ Income\", \"â“ Uncategorized Transactions\"])\n",
    "    \n",
    "    with tab1:\n",
    "        st.subheader(\"ðŸ“Š Spending Transactions\")\n",
    "        spending_df = df[df['action'].str.lower() == 'spend']\n",
    "        if not spending_df.empty:\n",
    "            st.dataframe(spending_df)\n",
    "        else:\n",
    "            st.warning(\"âš ï¸ No spending transactions found.\")\n",
    "    \n",
    "    with tab2:\n",
    "        st.subheader(\"ðŸ’° Saving Transactions\")\n",
    "        saving_df = df[df['action'].str.lower() == 'save']\n",
    "        if not saving_df.empty:\n",
    "            st.dataframe(saving_df)\n",
    "        else:\n",
    "            st.warning(\"âš ï¸ No saving transactions found.\")\n",
    "    \n",
    "    with tab3:\n",
    "        st.subheader(\"ðŸ“ˆ Income Transactions\")\n",
    "        income_df = df[df['action'].str.lower() == 'income']\n",
    "        if not income_df.empty:\n",
    "            st.dataframe(income_df)\n",
    "        else:\n",
    "            st.warning(\"âš ï¸ No income transactions found.\")\n",
    "    \n",
    "    with tab4:\n",
    "        st.subheader(\"â“ Uncategorized Transactions\")\n",
    "        if not uncategorized_df.empty():\n",
    "            st.dataframe(uncategorized_df)\n",
    "        else:\n",
    "            st.warning(\"âš ï¸ No uncategorized transactions found.\")\n",
    "    \n",
    "    # Feedback Section\n",
    "    st.sidebar.subheader(\"ðŸ’¡ Feedback & Suggestions\")\n",
    "    feedback_text = st.sidebar.text_area(\"How can we improve this dashboard?\")\n",
    "    if st.sidebar.button(\"Submit Feedback\"):\n",
    "        with open(feedback_file, \"a\") as f:\n",
    "            f.write(feedback_text + \"\\n\")\n",
    "        st.sidebar.success(\"âœ… Thank you for your feedback!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
